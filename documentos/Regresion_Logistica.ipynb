{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2fc6f3-e9b1-43d5-ac43-95254d89ad24",
   "metadata": {},
   "source": [
    "# Regresion Logistica: Deteccion de SPAM\n",
    "\n",
    "En este ejercico se muestran los fundamentos de la regresion logistica, planteando uno de los primeros problemas que fueron solucionados mediante el uso ded tecnicas de Machine Learning: La deteccion de SPAM\n",
    "\n",
    "\n",
    "##  Enunciado del ejercicio.\n",
    "Se propone la construccion de un sistema de aprendizaje automatico capaz de predecir si un correo determinado se corresponde con un correo SPAM o no, para ello se utilizara el siguente DatSet:\n",
    "\n",
    "##### [2007_TE _Public_Spam_Corpus (https://plg.uwaterloo.ca/~gvcormac/treccorpus07/)]\n",
    "The corpus trec07p contains 75,419 messages:\n",
    "\n",
    "    25220 ham\n",
    "    50199 spam\n",
    "\n",
    "These messages constitute all the messages delivered to a particular\n",
    "server between these dates:\n",
    "\n",
    "    Sun, 8 Apr 2007 13:07:21 -0400\n",
    "    Fri, 6 Jul 2007 07:04:53 -0400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185b3472-6ff6-4a69-9db5-45c0c3e4e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta clase se facilita el procesamiento de correos electronicos \n",
    "\n",
    "# que poseen codigo html.\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.fed = []\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235ed2d4-30f7-479d-aeae-b6db38f1eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion se encarga de eliminar los tags HTML\n",
    "# que se encunetren en el texto de los correos electronicos\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed184ff-f1f5-4181-83b9-bedd4b771c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phrack world News '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de eliminacion de los tads HTML de un texto\n",
    "t = '<tr><td align=\"left\"><ahref=\"../../issues/51/16.html#article\">Phrack world News </a><td>'\n",
    "strip_tags(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648b80d2-41b6-47a2-89be-066c54bedb68",
   "metadata": {},
   "source": [
    "Ademas de eliminar los posiblrs tags html que se encuentran en el correo electronico deben realizarse otras acciones para evitar que los mensajes contengan ruido inecesario. Entre ellas se encuentra la eliminacion de signos de puntuacion, eliminancion de los posibles campos de correo electronico que no sean relevantes o eliminacion de los afijos de una palabra manteniendo unicamente la raiz de la misma(stemming). La clase que se muestra a continuacion realiza estas transformaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49835052-4341-41a2-9a7b-e3a21e5dee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.stemmer = nltk.PorterStemmer()\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "        self.punctuation = list(string.punctuation)\n",
    "\n",
    "    def parse(self, email_path):\n",
    "        \"\"\"Parse an email.\"\"\"\n",
    "        with open(email_path, errors = 'ignore') as e:\n",
    "            msg = email.message_from_file(e)\n",
    "        return None if not msg else self.get_email_content(msg)\n",
    "\n",
    "    def get_email_content(self, msg):\n",
    "        \"\"\"Extract the email content.\"\"\"\n",
    "        subject = self.tokenize(msg['Subject']) if msg ['Subject'] else []\n",
    "        body = self.get_email_body(msg.get_payload(),\n",
    "                                  msg.get_content_type())\n",
    "        content_type = msg.get_content_type()\n",
    "        # Return the content of the email\n",
    "        return {\"subject\": subject,\n",
    "               \"body\": body,\n",
    "               \"content_type\": content_type}\n",
    "\n",
    "    def get_email_body(self, payload, content_type):\n",
    "        \"\"\"Extract the body of the email.\"\"\"\n",
    "        body = []\n",
    "        if type(payload) is str and content_type == 'text/plain':\n",
    "            return self.tokenize(payload)\n",
    "        elif type(payload) is str and content_type == 'text/html':\n",
    "            return self.tokenize(strip_tags(payload))\n",
    "        elif type(payload) is list:\n",
    "            for p in payload:\n",
    "                body += self.get_email_body(p.get_payload(), \n",
    "                                           p.get_content_type())\n",
    "        return body\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Transform a text string in tokens. Perform two main actons,\n",
    "        clean the puntuaction symbols and do stemming of the text\"\"\"\n",
    "        for c in self.punctuation:\n",
    "            text = text.replace(c, \"\")\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        tokens = list(filter(None, text.split(\" \")))\n",
    "        # Stremming of the tokens\n",
    "        return [self.stemmer.stem(w) for w in tokens if w not in self.stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24b681-bbff-4593-9c1b-7865c30eb45d",
   "metadata": {},
   "source": [
    "Lectura de un correo en formato .raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27a5bc-eb3e-4b33-8471-54cfadfd2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inmail = open(\"datasets/datasets/trec07p/data/emails.csv\").read()\n",
    "print(inmail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d2f69-bbf1-4bfc-84fb-6456639e97af",
   "metadata": {},
   "source": [
    "##### Parsing del correo electronio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013b099-aadc-4312-ae8b-7550f7f42d3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = Parser()\n",
    "p.parse(\"datasets/datasets/trec07p/data/inmail.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4954f20e-a167-40fe-bbd5-4991feed55b9",
   "metadata": {},
   "source": [
    "##### Lectura del indice\n",
    "Estas funciones complementarias se encargan de cargar en memoria la ruta de cada correo electronico y su etiqueta correspondinete.\n",
    "{Spam,ham}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66015837-0f50-4acf-8a15-12649c543364",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = open(\"datasets/datasets/trec07p/full/index\").readlines()\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f2139-917c-461f-9d02-650b0680b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATASET_PATH = \"datasets/datasets/trec07p\"\n",
    "\n",
    "def parse_index(path_to_index, n_elements):\n",
    "    ret_indexes = []\n",
    "    index = open(path_to_index).readlines()\n",
    "    for i in range(n_elements):\n",
    "        mail = index[i].split(\" ../\")\n",
    "        label = mail[0]\n",
    "        path = mail[1].strip() \n",
    "        ret_indexes.append({\"label\": label, \"email_path\": os.path.join(DATASET_PATH, path)})\n",
    "\n",
    "    return ret_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed19480-3192-4af5-ba51-ef8b6387ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(index):\n",
    "    p = Parser()\n",
    "    pmail = p.parse(index[\"email_path\"])\n",
    "    return pmail, index[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b653cf0-6b08-4b16-9762-36112cad3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = parse_index(\"datasets/datasets/trec07p/full/index\", 10)\n",
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075c09a-f6dd-47c1-9f3c-629c0aed615a",
   "metadata": {},
   "source": [
    "##### Prepocesamiento del DataSet.\n",
    "\n",
    "Con las funciones presentadas anteriormente se permite la lectura de los codigos electronicos de manera programatica  y el procesamineto de los mismos para eliminar aquellos componentes componentes que no resultan de utilidad para la deteccion de correos de SPAM. Sin embargo, cada uno de los correos sigue estando representado por un diccionario de python con una serie de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8ab94-ad17-4aed-81ff-3fa8ffe8e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el indice y las etiquetas en memoria\n",
    "index = parse_index(\"datasets/datasets/trec07p/full/index\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee868dc-e3a6-44d1-a3b4-04115cb83b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos primer correo\n",
    "\n",
    "import os\n",
    "\n",
    "open(index[0][\"email_path\"]).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329e42b-c215-4ccd-a954-084956502315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsear el primer correo\n",
    "mail, label = parse_email(index[0])\n",
    "print(\"El correo es: \\n\",label)\n",
    "print(mail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49bb5eb-d84a-4a0b-87c2-9d5640d38c1d",
   "metadata": {},
   "source": [
    "El algoritmo de Regresion LogÍstica no es capaz de ingerir texto como parte del DataSet. Por lo tanto deben de aplicarse una serie de funciones adicionales que transformen el texto de los correos electrónicos parseados en una representación númerica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63269454-f9ad-418e-9f75-02f1291ae3aa",
   "metadata": {},
   "source": [
    "### Aplicacion de countVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20cba5a-08f1-4491-af0c-3121d5b9dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Preparacion del email en una cadena de texto.\n",
    "prep_email = [\" \".join(mail['subject']) + \" \".join(mail['body'])]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit(prep_email)\n",
    "\n",
    "print(\"\\n\\ne-mail:\", prep_email, \"\\n\")\n",
    "print(\"Caracteristicas de entrada:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf935f5-67c0-4509-991a-d090cce53cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(prep_email)\n",
    "print(\"\\nValues:\\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151230ae-1582-4878-980d-10ef38591ee7",
   "metadata": {},
   "source": [
    "#### Aplicacion de OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7539a37-3ca3-43aa-8e67-e10a64cfc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "prep_email = [[w] for w in mail['subject'] +mail['body']]\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "X = enc.fit_transform(prep_email)\n",
    "\n",
    "print(\"Features:\\n\", enc.get_feature_names_out(), \"\\n\")\n",
    "print(\"Values:\", X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c33d9a-6993-492f-88e0-d9c3538b822c",
   "metadata": {},
   "source": [
    "#### Funciones auxiliares para el procesamiento del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee2dca-28e0-4869-903d-fc436bc5cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prep_dataset(index_path, n_elements):\n",
    "    X = []\n",
    "    y = []\n",
    "    indexes = parse_index(index_path, n_elements)\n",
    "    for i in range(n_elements):\n",
    "        print(\"\\rParsing email: {0}\".format(i+1), end = '')\n",
    "        mail, label = parse_email(indexes[i])\n",
    "        X.append(\" \".join(['subject']) + \" \".join(mail['body']))\n",
    "        y.append(label)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92dcbf0-018e-4bf6-8fe5-c2467c98c983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Leer unicamente un subconjunto de 1000 correos electronicos.\n",
    "X_train, y_train = create_prep_dataset(\"datasets/datasets/trec07p/full/index\", 1000)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7736a965-5393-4b05-8933-417c37c5a3d9",
   "metadata": {},
   "source": [
    "##### Aplicar vectorizacion a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8379dc1-3b49-4814-b78f-10e29cac5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5355be-3870-4aea-9842-d688dca98e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.toarray())\n",
    "print(\"\\nFeatures\", len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31058f91-8c86-4d01-b630-227ee05290f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(X_train.toarray(), columns=[vectorizer.get_feature_names_out()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f9f6c-4b46-4d70-bba3-52bd3c851b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1161734-d52f-4213-8b4b-fbcf44d9fcbc",
   "metadata": {},
   "source": [
    "#### Entrenamiento del algoritmo de Regresion Logistica con en DataSet preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6085e-3ca7-491a-afd2-ca755c2bcf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01957d6-15e7-4386-9e0a-7397181d128a",
   "metadata": {},
   "source": [
    "# 4.- Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d54f3d-a7c1-4f7d-ba34-d9cbfe619a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de un DataSet de correos nuevos.\n",
    "\n",
    "# Leer 1500 correos de nuestro DataSet y quedarnos unicamente con los 500 ultimos correos electronicos, los cuales no se han utilizado\n",
    "# Para entrenar el  algoritmo\n",
    "X,y = create_prep_dataset(\"datasets/datasets/trec07p/full/index\", 150)\n",
    "X_test = X[100:]\n",
    "y_test = y[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67cb34f-43aa-42ac-8d09-7fa836a36739",
   "metadata": {},
   "source": [
    "##### Preprpcesamiento de los correos electronicos con el vectorizado creado anteriormenete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0a823-f189-4750-8165-da3e04cebcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =  vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f64814b-3353-40e8-b295-942785727087",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529fe41-2efe-45b7-9744-0978e645433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediccion\\n\", y_pred)\n",
    "print(\"\\nEtiquetas Reales\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e31598-5aa4-4243-92f4-23d63173b9b5",
   "metadata": {},
   "source": [
    "#### Evaluacion de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc25e1-1c50-4940-ad20-79b5c8db4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4b5d7-4cf4-41c6-81d9-de26dbf08605",
   "metadata": {},
   "source": [
    "# 5.- Aumentando el DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fe4f6-6e5f-4cdc-8d08-fca0549a3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer 20000 correos electronicos\n",
    "X, y = create_prep_dataset(\"datasets/datasets/trec07p/full/index\", 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1fc8b5-b193-4e64-9f9e-2bc065ab1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos 15,000 para entrenar el algoritmo y 5,000 para realizar proebas\n",
    "X_train, y_train = X[:15000], y[:15000]\n",
    "X_test, y_test = X[15000:], y[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7bc095-745c-4476-8e10-44687776a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2db427-5a67-4464-9c7d-d77296b5e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c483944-9e03-4835-9398-b5906e80933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(X_test)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab11c28-649f-4c02-a767-9b17a0a7c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f6a14-7f41-4948-abaf-a6f2c30a925a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
